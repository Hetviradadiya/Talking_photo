# import os
# import subprocess
# from django.conf import settings
# import sys

# def generate_video(face_path, audio_path, output_path):
#     base_dir = settings.BASE_DIR  # project root
#     inference_script = os.path.join(base_dir, 'Wav2Lip', 'inference.py')
#     checkpoint_path = os.path.join(base_dir, 'Wav2Lip', 'checkpoints', 'wav2lip.pth')

#     command = [
#         sys.executable, # Use virtual environment's Python
#         inference_script,
#         '--checkpoint_path', checkpoint_path,
#         '--face', face_path,
#         '--audio', audio_path,
#         '--outfile', output_path
#     ]

#     subprocess.run(command, check=True)


# utils/lipsync.py

import os
import subprocess
from django.conf import settings
import sys

def generate_video(face_path, audio_path, output_path):
    base_dir = settings.BASE_DIR
    sadtalker_path = os.path.join(base_dir, 'SadTalker')  # Path to SadTalker folder
    inference_script = os.path.join(sadtalker_path, 'inference.py')
    checkpoints_path = os.path.join(sadtalker_path, 'checkpoints')

    command = [
        sys.executable,
        inference_script,
        '--driven_audio', audio_path,
        '--source_image', face_path,
        '--checkpoint_dir', checkpoints_path,
        '--result_dir', os.path.dirname(output_path),
        '--pose_style', '0',  # You can customize this
        '--enhancer', 'gfpgan',  # Optional: improve quality
        '--batch_size', '1',
        '--size', '256',
        '--still'  # Use still mode for better stability with photos
    ]

    subprocess.run(command, check=True)

    # SadTalker saves output as driven_audio.mp4 â€” rename/move if needed
    generated_name = 'driven_audio.mp4'
    final_path = os.path.join(os.path.dirname(output_path), generated_name)
    if os.path.exists(final_path):
        os.rename(final_path, output_path)
